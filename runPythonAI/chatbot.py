import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from load_documents import load_documents  

# Load model v√† FAISS index
model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")
index = faiss.read_index("faiss_index.bin")
documents = load_documents("documents/")

def is_valid_question(question):
    if len(question) <= 9:  # C√¢u qu√° ng·∫Øn
        return False
    if all(char in "?.,!1234567890" for char in question):  # Ch·ª©a to√†n k√Ω t·ª± ƒë·∫∑c bi·ªát
        return False
    return True

# H√†m l·∫•y c√¢u tr·∫£ l·ªùi cho API
def get_answer(question):
    if not is_valid_question(question):
        return "üòº‚ùå Vui l√≤ng ƒë·∫∑t c√¢u h·ªèi r√µ r√†ng h∆°n."

    query_vector = model.encode([question])
    distances, indices = index.search(np.array(query_vector), 1)

    best_match_idx = indices[0][0]
    best_distance = distances[0][0]

    # Debug: Xem ch·ªâ s·ªë FAISS ch·ªçn
    print(f"üîç C√¢u h·ªèi: {question}")
    print(f"üìå Best match index: {best_match_idx}, Distance: {best_distance}")
    print(f"üìñ N·ªôi dung t√¨m th·∫•y: {documents[best_match_idx][:100]}...\n")

    # Ki·ªÉm tra n·∫øu c√¢u h·ªèi kh√¥ng ƒë·ªß ƒë·ªô ch√≠nh x√°c
    THRESHOLD = 1.0
    if best_distance > THRESHOLD:
        return (
            "ü§ñ Xin l·ªói, t√¥i ch∆∞a c√≥ th√¥ng tin v·ªÅ c√¢u h·ªèi n√†y. "
            "B·∫°n c√≥ th·ªÉ th·ª≠ h·ªèi l·∫°i ho·∫∑c li√™n h·ªá h·ªó tr·ª£ kh√°ch h√†ng."
        )

    if isinstance(documents[best_match_idx], str):
        return documents[best_match_idx].replace("==>", "üòº‚úÖ").replace("?", ":")
    else:
        return documents[best_match_idx]  # Chuy·ªÉn v·ªÅ chu·ªói n·∫øu c·∫ßn
